{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1\n",
    "\n",
    "\n",
    "### Целью этого задания является знакомство со стандартными контейнерами и некторыми функциями из стандартных библиотек для машинного обучения.\n",
    "\n",
    "Напишите наивный байесовский классификатор и сравните его с реализацией NaiveBayesClassifier из библиотеки nltk.\n",
    "\n",
    "Написанный вами классификатор должен обладать следубщими свойствами:\n",
    "<ul>\n",
    "<li>В предложенном интерфейсе класса должны быть реализованы все методы и все поля. Для их хранения предподсчитанных данных рекомендуется использовать контейнеры Counter или defaultdict из библиотеки collections. Для предсказания категории рекомендуется использовать numpy.</li>\n",
    "<li>Должна использоваться модель, предложенная в теории.</li>\n",
    "<li>Точность предсказаний не менее <b>0.9</b>!</li>\n",
    "<li>После реализации класса протестируйте его с помощью кроссвалидации с k=10. Рекомендуется использовать класс KFold из библиотеки sklearn.</li>\n",
    "<li>Постройте постройте диаграмму размаха для классификаторов (своего и из библиотеки).</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теория"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теория находится в файле problems1-theory.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\Lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk import NaiveBayesClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прочитайте данные из файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"ham-spam.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализуйте все методы в классе NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#читаем файл.\n",
    "mails = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayes(object):\n",
    "    \"\"\"\n",
    "    Наивный байесовский классификатор.\n",
    "    Для каждого входного сообщения слово учитывается один раз при расчете итоговой вероятности.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    category_priors : default | None, optional, default None\n",
    "        Априорные вероятности категорий.\n",
    "        Если None, то классификатор должен сам их вычислить.\n",
    "\n",
    "    weight : float, optional, default 1\n",
    "        Вес одного слова в формуле взвешенной вероятности\n",
    "\n",
    "    supposed_prob : float, optional, default 0.5\n",
    "        Предполагаемая вероятность слова в категории\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, category_priors=None, weight=1, supposed_prob=0.5):\n",
    "        self.category_priors = category_priors\n",
    "        self.weight = weight\n",
    "        self.supposed_prob = supposed_prob\n",
    "\n",
    "        # Количество отдельных слов в заданной категории\n",
    "        self.feature_category_counts = defaultdict(Counter)\n",
    "\n",
    "        # Количество всех документов в данной категории\n",
    "        self.category_doc_counts = Counter()\n",
    "\n",
    "        # Количество встреч слова во всех сообщениях\n",
    "        self.feature_counts = Counter()\n",
    "        \n",
    "        self.words_number = 0\n",
    "        self.words_in_categories = Counter()\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "        Производит обучение наивного байесовского классификатора.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x_train : list of list of str | list of str | str\n",
    "            Входной текст описывается строкой, которую будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "            Может быть передано несколько сообщений, которые будут токенезированы, если необходимо.\n",
    "\n",
    "        y_train : list of str\n",
    "            содержит список меток (названий категорий) для сообщений из x_train\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self\n",
    "        \"\"\"\n",
    "        # делаем list of list of str.\n",
    "        if type(x_train) == str:\n",
    "            x_train = [x_train.split()]\n",
    "        elif type(x_train) == list and type(x_train[0]) == str:\n",
    "            for i in range(len(x_train)):\n",
    "                x_train[i] = x_train[i].split()\n",
    "        \n",
    "        # Подсчитываем количество категорий, документов и слов в каждой категории\n",
    "        # и количество встреч слова во всех сообщениях\n",
    "        for i in range(len(x_train)):\n",
    "            for j in range(len(x_train[i])):\n",
    "                self.feature_category_counts[y_train[i]][x_train[i][j]] += 1\n",
    "                self.feature_counts[x_train[i][j]] += 1\n",
    "            self.category_doc_counts[y_train[i]] += 1\n",
    "         \n",
    "        # Считаем общее количество слов.\n",
    "        for i in self.feature_counts.values():\n",
    "            self.words_number += i\n",
    "            \n",
    "        # Считаем количество слов в каждой категории.\n",
    "        # c_c - current category\n",
    "        # w - категория\n",
    "        for w in self.feature_category_counts.keys():\n",
    "            c_c = 0\n",
    "            for x in self.feature_category_counts[w].values():\n",
    "                c_c += x\n",
    "            self.words_in_categories[w] = c_c\n",
    "                \n",
    "        # Если априорные вероятности категорий не заданы, то надо аппроксимировать их.\n",
    "        if self.category_priors is None:\n",
    "            self.category_priors = {}\n",
    "            for w in self.feature_category_counts.keys():\n",
    "                self.category_priors[w] = self.words_in_categories[w] / self.words_number\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, text):\n",
    "        \"\"\"\n",
    "        Предсказывает метки категорий для text.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of list of str | list of str | str\n",
    "            Входной текст описывается строкой, которую будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "            Может быть передано несколько сообщений, которые будут токенезированы, если необходимо.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        categories : list of str\n",
    "            Возвращает названия категорий для text.\n",
    "        \"\"\"\n",
    "        if type(text) == str:\n",
    "            text = [text.split()]\n",
    "        elif type(text) == list and type(text[0]) == str:\n",
    "            for i in range(len(text)):\n",
    "                text[i] = text[i].split()\n",
    "        \n",
    "        # будем хранить в нем категориии и подсчитанные вероятности, чтобы потом выбрать max.\n",
    "        cat_to_choose, categories = {}, []\n",
    "        for i in range(len(text)):\n",
    "            cat_to_choose = self.get_probs(text[i])\n",
    "            # ищем max.\n",
    "            category = list(cat_to_choose.keys())[0]\n",
    "            for cat in cat_to_choose.keys():\n",
    "                if cat_to_choose[cat] > cat_to_choose[category]:\n",
    "                    category = cat\n",
    "            \n",
    "            categories.append(category)\n",
    "                    \n",
    "            \n",
    "        return categories\n",
    "\n",
    "    def score(self, text, labels):\n",
    "        \"\"\"\n",
    "        Возвращает точность предсказаний на text для правильных категорий labels.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of list of str | list of str | str\n",
    "            Входной текст описывается строкой, которую будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "            Может быть передано несколько сообщений, которые будут токенезированы, если необходимо.\n",
    "        labels : list of str\n",
    "            Список категорий для каждого токена из text.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        acc : float\n",
    "            Точность предсказания.\n",
    "        \"\"\"\n",
    "        if type(text) == str:\n",
    "            text = [text.split()]\n",
    "        elif type(text) == list and type(text[0]) == str:\n",
    "            for i in range (len(text)):\n",
    "                text[i] = text[i].split()\n",
    "                \n",
    "        categories = self.predict(text)\n",
    "        acc = 0\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == categories[i]:\n",
    "                acc += 1\n",
    "        acc /= len(labels)\n",
    "        \n",
    "        return acc\n",
    "\n",
    "    def get_probs(self, text):\n",
    "        \"\"\"\n",
    "        Считает вероятности принадлежности текста (text) к каждой из категорий\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of str | str\n",
    "            Входной текст описывается строкой, которую будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        probs : list of float\n",
    "            Возвращает вероятности probs всех категорий для текста text\n",
    "            в порядке их следования в self.category_doc_counts.\n",
    "        \"\"\"\n",
    "        # Токенизируем текст, если это необходимо\n",
    "        if type(text) == str:\n",
    "            text = text.split()\n",
    "        # Удобнее возвращать словарь с названием категории и значением вероятности    \n",
    "        probs = {}\n",
    "        for cat in self.get_categories():\n",
    "            probs[cat] = self.get_category_prob(cat, text)\n",
    "\n",
    "        return probs\n",
    "\n",
    "    def get_category_prob(self, cat, text):\n",
    "        \"\"\"\n",
    "        Считает логарифм вероятность принадлежности сообщения text к категории cat.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cat : str\n",
    "            Название категории.\n",
    "\n",
    "        text : list of str\n",
    "            Список из слов.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        log_prob : float\n",
    "            Возвращает логарифм вероятности категории cat для текста text.\n",
    "        \"\"\"\n",
    "        log_prob = 0\n",
    "        for i in range(len(text)):\n",
    "            w_prob = self.get_weighted_feature_prob(cat, text[i])\n",
    "            if w_prob == 0:\n",
    "                w_prob = self.supposed_prob\n",
    "            log_prob += log(w_prob)\n",
    "        \n",
    "        log_prob += log(self.category_priors[cat])\n",
    "        return log_prob\n",
    "\n",
    "    def get_weighted_feature_prob(self, cat, feature):\n",
    "        \"\"\"\n",
    "        Вычисляет взвешенную вероятность P(Слово|Категория).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cat : str\n",
    "            Название категории.\n",
    "\n",
    "        feature : str\n",
    "            Слово из текста.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        prob : float\n",
    "            Возвращает взвешенную вероятность слова feature при условии категории cat.\n",
    "        \"\"\"\n",
    "        total = self.words_number\n",
    "        \n",
    "        # Считаем вероятность P(Слово|Категория). \n",
    "        u_prob = self.feature_category_counts[cat][feature] / self.words_in_categories[cat]\n",
    "        \n",
    "        # Считаем взвешенную вероятность P(Слово|Категория).\n",
    "        prob = (self.weight * self.supposed_prob + total * u_prob) / (self.weight + total)\n",
    "\n",
    "        return prob\n",
    "\n",
    "    def get_categories(self):\n",
    "        \"\"\"\n",
    "        Возвращает список названий всех категорий.\n",
    "        Returns\n",
    "        -------\n",
    "        cat_list : list of str\n",
    "        \"\"\"\n",
    "        cat_list = self.feature_category_counts.keys()\n",
    "        return cat_list\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравните вашу реализацию и реализацию из библиотеки nltk\n",
    "\n",
    "Для использования классификатора из библиотеки не забудьте предподготовить данные. Для подсчета точности этого классификатора можете использовать accuracy_score из метрик sklearn. Для подсчета точности предсказаний вашего классификатора используйте функцию score, которую вы опишете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2893/2893 [00:40<00:00, 71.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# Предобработка данных для классификатора nltk, если требуется\n",
    "all_words = set()\n",
    "msg, words = [], []\n",
    "for i in range(len(mails)):\n",
    "    msg.append(mails['msg'][i].split())\n",
    "    words.append(set(msg[i]))\n",
    "    all_words.update(msg[i])\n",
    "    \n",
    "target = np.array(mails['target'])\n",
    "msg = np.array(msg)\n",
    "\n",
    "nltk_mails = np.array([({word: (word in words[i]) for word in all_words}, target[i]) for i in tqdm(range(len(mails)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Используйте процедуру KFold для проверки качества классификаторов\n",
    "k_fold_list = list(KFold(len(msg), n_folds=10, shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:20<00:00,  2.07s/it]\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "for it_train, it_test in tqdm(k_fold_list):\n",
    "    x_train = msg[it_train]\n",
    "    x_test = msg[it_test]\n",
    "    y_train = target[it_train]\n",
    "    y_test = target[it_test]\n",
    "\n",
    "    classifier = NaiveBayes()\n",
    "    classifier.fit(x_train, y_train)\n",
    "\n",
    "    prediction = classifier.predict(x_test)\n",
    "    \n",
    "    accuracy = accuracy_score(prediction, y_test)\n",
    "    accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [27:15<00:00, 163.58s/it]\n"
     ]
    }
   ],
   "source": [
    "#nltk\n",
    "nltk_accuracies = []\n",
    "for it_train, it_test in tqdm(k_fold_list):\n",
    "    y_test = target[it_test]\n",
    "    \n",
    "    train = nltk_mails[it_train]\n",
    "    test = nltk_mails[it_test, 0]\n",
    "    \n",
    "    nltk_classifier = NaiveBayesClassifier.train(train)\n",
    "    \n",
    "    nltk_prediction = nltk_classifier.classify_many(test)\n",
    "    \n",
    "    nltk_accuracy = accuracy_score(nltk_prediction, y_test)\n",
    "    \n",
    "    nltk_accuracies.append(nltk_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Постройте графики размаха для двух классификаторов на одной фигуре.\n",
    "\n",
    "Рекомендуется использовать встроенные функции построения графиков в pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2c2efea1e10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c2efea19b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(nltk_accuracies).boxplot()\n",
    "pd.DataFrame(accuracies).boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
